---
description: Visualize PyTorch Lightning models with W&B
---

# PyTorch Lightning

PyTorch Lightning provee un wrapper liviano para organizar tu c√≥digo PyTorch y para agregar f√°cilmente caracter√≠sticas avanzadas tales como [entrenamiento distribuido](https://pytorch-lightning.readthedocs.io/en/latest/multi_gpu.html) y [precisi√≥n de 16 bits](https://pytorch-lightning.readthedocs.io/en/latest/amp.html)       . W&B provee un wrapper liviano para registrar tus experimentos de ML. Estamos incorporados directamente en la biblioteca PyTorch Lightning, as√≠ que siempre puedes fijarte en [su documentaci√≥n](https://pytorch-lightning.readthedocs.io/en/latest/loggers.html#weights-and-biases).

## ‚ö° Yendo a la velocidad de la luz con solo dos l√≠neas:

```python
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning import Trainer

wandb_logger = WandbLogger()
trainer = Trainer(logger=wandb_logger)
```

## ‚úÖ ¬°Comprueba ejemplos reales!

Hemos creado algunos ejemplos para que veas c√≥mo funciona la integraci√≥n:

*  [Demostraci√≥n en Google Colab](https://colab.research.google.com/drive/16d1uctGaw2y9KhGBlINNTsWpmlXdJwRW?usp=sharing) con optimizaci√≥n de hiperpar√°metros
*  [Tutorial](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch-lightning/Supercharge_your_Training_with_Pytorch_Lightning_%2B_Weights_%26_Biases.ipynb): Sobrecarga tu Entrenamiento con PyTorch Lightning + Weights & Biases
*  [Segmentaci√≥n Sem√°ntica con Lightning](https://app.wandb.ai/borisd13/lightning-kitti/reports/Lightning-Kitti--Vmlldzo3MTcyMw): optimiza redes neuronales para veh√≠culos aut√≥nomos
*  [Una gu√≠a paso a paso](https://app.wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-%26-Biases--Vmlldzo2NjQ1Mw) para hacer el seguimiento del desempe√±o de tu modelo de Lightning

## **üíª** Referencia de la API

### `WandbLogger`

 Par√°metros Optativos:

* **name \(str\)** ‚Äì visualiza el nombre para la ejecuci√≥n.
* **save\_dir** \(_str_\) ‚Äì ruta donde son guardados los datos \(por defecto, el directorio wandb\).
* **offline** \(_bool_\) ‚Äì ejecuta fuera de l√≠nea \(los datos pueden ser transmitidos m√°s tarde a los servidores de wandb\).
* **id** \(_str_\) ‚Äì establece la versi√≥n, principalmente usado para reanudar una ejecuci√≥n previa.
* **version** \(_str_\) ‚Äì igual que version \(legacy\).
* **anonymous** \(_bool_\) ‚Äì habilita o deshabilita expl√≠citamente el registro an√≥nimo.
* **project** \(_str_\) ‚Äì el nombre del proyecto al que pertenece esta ejecuci√≥n.
* **log\_model** \(_bool_\) ‚Äì guarda puntos de control en el directorio wandb para subir a los servidores de W&B.
* **prefix** \(_str_\) ‚Äì string para poner al comienzo de las claves de las m√©tricas.
* **sync\_step** \(_bool_\) - sincroniza el paso del Entrenador con el paso de wandb \(por defecto es True\).
* **\*\*kwargs** ‚Äì  Los argumentos adicionales como `entity`, `group`, `tags`, etc., usados por `wandb.init`, pueden ser pasados como argumentos de palabras claves en este registrador.

### **`WandbLogger.watch`**

Registra la topolog√≠a del modelo, as√≠ tambi√©n como, de forma opcional, los gradientes y los pesos.

```python
wandb_logger.watch(model, log='gradients', log_freq=100)
```

Par√°metros:

* **model** \(_nn.Module_\) ‚Äì modelo que se va a registrar.
* **log** \(_str_\) ‚Äì puede ser ‚Äúgradients‚Äù \(por defecto\), ‚Äúparameters‚Äù, ‚Äúall‚Äù o None.
* **log\_freq** \(_int_\) ‚Äì cuenta de pasos entre el registro de los gradientes y los par√°metros \(por defecto es 100\)

### **`WandbLogger.log_hyperparams`**

Registra la configuraci√≥n de los hiperpar√°metros.

Nota: esta funci√≥n es llamada autom√°ticamente cuando se usa LightningModule.save\_hyperparameters\(\)_`LightningModule.save_hyperparameters()`_

```python
wandb_logger.log_hyperparams(params)
```

Par√°metros

* **params** \(dict\)  ‚Äì diccionario con los nombres de los hiperpar√°metros como claves, y los valores de configuraci√≥n como valores

### `WandbLogger.log_metrics`

Registra m√©tricas de entrenamiento.

Nota: esta funci√≥n es llamada autom√°ticamente por `LightningModule.log('metric', value)`

```python
wandb_logger.log_metrics(metrics, step=None)
```

Par√°metros:

* **metric \(numeric\)** ‚Äì diccionario con nombres de m√©tricas como claves y cantidades medidas como valores
* **step \(int\|None\)** ‚Äì n√∫mero de paso en el que las m√©tricas deber√≠an registrarse

\*\*\*\*

